<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>lazydf.compression API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>lazydf.compression</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#  Copyright (c) 2021. Davi Pereira dos Santos
#  This file is part of the lazydf project.
#  Please respect the license - more about this in the section (*) below.
#
#  lazydf is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  lazydf is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with lazydf.  If not, see &lt;http://www.gnu.org/licenses/&gt;.
#
#  (*) Removing authorship by any means, e.g. by distribution of derived
#  works or verbatim, obfuscated, compiled or rewritten versions of any
#  part of this work is illegal and unethical regarding the effort and
#  time spent here.
import json
import pickle
from importlib import import_module

import bson
from bson import InvalidDocument
from orjson import OPT_SORT_KEYS, orjson, dumps


def topickle(obj, ensure_determinism):
    try:
        try:
            prefix = b&#34;05pckl_&#34;
            dump = pickle.dumps(obj, protocol=5)
        except Exception as e:
            if ensure_determinism:  # pragma: no cover
                print(e)
                raise NondeterminismException(&#34;Cannot serialize deterministically.&#34;)
            import dill

            prefix = b&#34;05dill_&#34;
            dump = dill.dumps(obj, protocol=5)

        blob = prefix + dump
        return blob
    except KeyError as e:  # pragma: no cover
        if str(e) == &#34;&#39;__getstate__&#39;&#34;:  # pragma: no cover
            raise Exception(&#34;Unpickable value:&#34;, type(obj))
        else:
            raise e


def frompickle(blob):
    prefix = blob[:7]
    blob = blob[7:]
    if prefix == b&#34;05pckl_&#34;:
        return pickle.loads(blob)
    elif prefix == b&#34;05dill_&#34;:
        import dill

        return dill.loads(blob)


m = {&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;: b&#34;00pddf_&#34;, &#34;&lt;class &#39;pandas.core.series.Series&#39;&gt;&#34;: b&#34;00pdsr_&#34;}


def traversal_enc(obj, ensure_determinism, unsafe_fallback):
    if isinstance(obj, bytes):
        return obj
    try:
        return b&#34;00json_&#34; + orjson.dumps(obj)
    except TypeError as e:
        pass
    try:
        return b&#34;00bson_&#34; + bson.encode({&#34;_&#34;: obj})
    except InvalidDocument as e:
        pass
    except OverflowError as o:
        if &#34;8-byte ints&#34; in str(o) and isinstance(obj, int):
            return b&#34;00bint_&#34; + str(obj).encode()
    klass = str(obj.__class__)
    if klass in [&#34;&lt;class &#39;numpy.ndarray&#39;&gt;&#34;]:
        return serialize_numpy(obj, ensure_determinism, unsafe_fallback)
    if klass in [&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;, &#34;&lt;class &#39;pandas.core.series.Series&#39;&gt;&#34;]:
        return serialize_numpy(obj.to_numpy(), ensure_determinism, unsafe_fallback, m[klass])
    if isinstance(obj, list):
        lst_of_bins = []
        for o in obj:
            lst_of_bins.append(traversal_enc(o, ensure_determinism, unsafe_fallback))
        return b&#34;00trav_&#34; + bson.encode({&#34;_&#34;: lst_of_bins})
    if unsafe_fallback:
        return topickle(obj, ensure_determinism)
    raise Exception(f&#34;Cannot pack {type(obj)}.&#34;)


def traversal_dec(dump):
    if isinstance(dump, bytes):
        header = dump[2:7]
        blob = dump[7:]
        if header == b&#34;json_&#34;:
            return orjson.loads(blob)
        if header == b&#34;bson_&#34;:
            return bson.decode(blob)[&#34;_&#34;]
        if header == b&#34;bint_&#34;:
            return int(blob.decode())
        if header == b&#34;nmpy_&#34;:
            return deserialize_numpy(blob)
        if header == b&#34;pddf_&#34;:
            from pandas import DataFrame

            return DataFrame(deserialize_numpy(blob))
        if header == b&#34;pdsr_&#34;:
            from pandas import Series

            return Series(deserialize_numpy(blob))
        if header == b&#34;trav_&#34;:
            return traversal_dec(bson.decode(blob)[&#34;_&#34;])
        if header in [b&#34;pckl_&#34;, b&#34;dill_&#34;]:
            return frompickle(dump)
        return dump
    if isinstance(dump, (int, str, bool)):
        return dump
    if isinstance(dump, list):
        lst = []
        for d in dump:
            lst.append(traversal_dec(d))
        return lst
    if isinstance(dump, dict):
        dic = {}
        for k, v in dump.items():
            dic[k] = traversal_dec(v)
        return dic
    raise Exception(f&#34;Cannot unpack {type(dump)}.&#34;)


def pack(obj, ensure_determinism, unsafe_fallback, compressed=True):
    r&#34;&#34;&#34;
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; d = [[np.array([[1, 2/3], [4, 5]]), {&#34;x&#34;: b&#34;dsa&#34;}], [b&#34;asd&#34;, 5]]
    &gt;&gt;&gt; blob = pack(d, ensure_determinism=True, unsafe_fallback=False)
    &gt;&gt;&gt; unpack(blob)
    [[array([[1.        , 0.66666667],
           [4.        , 5.        ]]), {&#39;x&#39;: b&#39;dsa&#39;}], [b&#39;asd&#39;, 5]]
    &gt;&gt;&gt; blob = pack(d, compressed=False, ensure_determinism=True, unsafe_fallback=False)
    &gt;&gt;&gt; unpack(blob)
    [[array([[1.        , 0.66666667],
           [4.        , 5.        ]]), {&#39;x&#39;: b&#39;dsa&#39;}], [b&#39;asd&#39;, 5]]
    &gt;&gt;&gt; import pandas as pd
    &gt;&gt;&gt; df = pd.DataFrame(np.array([[1, 2/3], [4, 5]]))
    &gt;&gt;&gt; unpack(pack(df, ensure_determinism=True, unsafe_fallback=False))
         0         1
    0  1.0  0.666667
    1  4.0  5.000000
    &#34;&#34;&#34;
    dump = traversal_enc(obj, ensure_determinism, unsafe_fallback)
    if compressed:
        import lz4.frame as lz4

        return b&#34;00lz4__&#34; + lz4.compress(dump)
    return dump


def unpack(blob):
    if blob[:7] == b&#34;00lz4__&#34;:
        import lz4.frame as lz4

        blob = lz4.decompress(blob[7:])
    return traversal_dec(blob)


class NondeterminismException(Exception):
    pass


def serialize_numpy(obj, ensure_determinism, unsafe_fallback, prefix=b&#34;00nmpy_&#34;):
    import numpy as np

    if isinstance(obj, np.ndarray):
        if obj.dtype in [np.dtype(object)]:
            if unsafe_fallback:
                return topickle(obj, ensure_determinism)
            raise Exception(f&#34;Cannot handle this ndarray dtype: &#39;{np.dtype(object)}&#39;&#34;)

        dims = str(len(obj.shape))
        dtype = str(obj.dtype)
        rest_of_header = f&#34;§{dims}§{dtype}§&#34;.encode() + integers2bytes(obj.shape)
        rest_of_header_len = str(len(rest_of_header)).encode()
        header = rest_of_header_len + rest_of_header
        # return header + lz4.compress(ascontiguousarray(obj).data)
        return prefix + header + obj.data.tobytes()
    raise Exception(f&#34;Cannot handle this type &#39;{type(obj)}&#39;, check its shape or dtype&#34;)


def deserialize_numpy(blob):
    import numpy as np

    rest_of_header_len = blob[:10].split(b&#34;\xc2\xa7&#34;)[0]
    first_len = len(rest_of_header_len)
    header_len = first_len + int(rest_of_header_len)
    dims, dtype, hw = blob[first_len + 2 : header_len].split(b&#34;\xc2\xa7&#34;)
    dims = int(dims.decode())
    dtype = dtype.decode().rstrip()
    shape = bytes2integers(hw.ljust(4 * dims))

    dump = memoryview(blob)[header_len:]
    # dump = lz4.decompress(dump)
    m = np.frombuffer(dump, dtype=dtype)
    if dims &gt; 1:
        m = np.reshape(m, newshape=shape)
    return m


def integers2bytes(lst, n=4) -&gt; bytes:
    &#34;&#34;&#34;Each int becomes N bytes. max=4294967294 for 4 bytes&#34;&#34;&#34;
    return b&#34;&#34;.join(d.to_bytes(n, byteorder=&#34;little&#34;) for d in lst)


def bytes2integers(bytes_content: bytes, n=4):
    &#34;&#34;&#34;Each 4 bytes become an int.&#34;&#34;&#34;
    return [int.from_bytes(bytes_content[i : i + n], &#34;little&#34;) for i in range(0, len(bytes_content), n)]


########################################################################################
########################################################################################
########################################################################################
########################################################################################


# def import_dependence(dep):
#     try:
#         return import_module(dep)
#     except ImportError as e:
#         raise Exception(f&#34;Missing {dep} library. Need a complete install\n&#34; &#34;pip install -U lazydf[full]&#34;)


# def custom_orjson_encoder(obj):
#     # E.g., pandas dataframes.
#     typ = str(type(obj))
#     if typ == &#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
#         return obj.to_numpy()
#     if typ == &#34;&lt;class &#39;pandas.core.series.Series&#39;&gt;&#34;:
#         return obj.to_numpy()
#     # if hasattr(obj, &#39;to_json&#39;):
#     #     # REMINDER: default_handler=str is to avoid infinite recursion, e.g., on iris.arff
#     #     txt = obj.to_json(force_ascii=False, default_handler=str)
#     #     return {&#34;_type_orjson&#34;: str(type(obj)), &#34;_obj.to_json()&#34;: txt}
#
#     # Numpy objects generic type and ndarray, keeping dtype.
#     if typ == &#34;&lt;class &#39;numpy.ndarray&#39;&gt;&#34;:
#         print(typ)
#         try:
#             return serialize_numpy(obj,ensure_determinism,unsafe_fallback) is None ???
#         except Exception as e:
#             print(e)
#             exit()
#
#     # try:
#     #     import numpy
#     #     if isinstance(obj, numpy.generic):
#     #         return {&#34;_type_orjson&#34;: str(obj.dtype), &#34;_numpy.asscalar(obj)&#34;: numpy.asscalar(obj)}
#     #     if isinstance(obj, numpy.ndarray):
#     #         return {&#34;_type_orjson&#34;: str(obj.dtype), &#34;_numpy.ndarray.tolist()&#34;: obj.tolist()}
#     # except ImportError as e:
#     #     pass
#
#     if isinstance(obj, bytes):
#         return obj.decode()  # nem qq byte vira string!
#     raise TypeError


# def json_object_hook_decoder(dic):
#     if &#34;_type_orjson&#34; in dic:
#         if &#34;_obj.to_json()&#34; in dic:
#             if dic[&#34;_type_orjson&#34;] == &#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;:
#                 m = import_dependence(&#34;pandas&#34;)
#                 return m.read_json(dic[&#34;_obj.to_json()&#34;])  # , default_handler=str)
#             if dic[&#34;_type_orjson&#34;] == &#34;&lt;class &#39;pandas.core.series.Series&#39;&gt;&#34;:
#                 m = import_dependence(&#34;pandas&#34;)
#                 # default_handler=callable
#                 return m.read_json(dic[&#34;_obj.to_json()&#34;], typ=dic[&#34;_type_orjson&#34;])
#             else:  # pragma: no cover
#                 raise Exception(f&#34;Cannot desserialize object of type &#39;{dic[&#39;_type_orjson&#39;]}&#39;&#34;)
#         if (c := &#34;_numpy.asscalar(obj)&#34;) in dic or (c := &#34;_numpy.ndarray.tolist()&#34;) in dic:
#             m = import_dependence(&#34;numpy&#34;)
#             dtype = &#34;str&#34; if len(dic[&#34;_type_orjson&#34;]) &gt; 10 else dic[&#34;_type_orjson&#34;]
#             return m.array(dic[c], dtype=dtype)
#     return dic


# def serialize_json(obj):
#     # r&#34;&#34;&#34;
#     # &gt;&gt;&gt; import numpy as np
#     # &gt;&gt;&gt; import math
#     # &gt;&gt;&gt; a = np.array([[1/3, 5/4], [1.3**6, &#34;text&#34;]])
#     # &gt;&gt;&gt; a
#     # array([[&#39;0.3333333333333333&#39;, &#39;1.25&#39;],
#     #        [&#39;4.826809000000001&#39;, &#39;text&#39;]], dtype=&#39;&lt;U32&#39;)
#     # &gt;&gt;&gt; b = np.array([[1/3,5/4], [1.3**6, 4]], dtype = np.int64)
#     # &gt;&gt;&gt; b
#     # array([[0, 1],
#     #        [4, 4]])
#     # &gt;&gt;&gt; c = np.array([[1/3,5/4], [1.3**6, 4]], dtype = np.int8)
#     # &gt;&gt;&gt; c
#     # array([[0, 1],
#     #        [4, 4]], dtype=int8)
#     # &gt;&gt;&gt; serialize_json([math.inf, a, b, c])
#     # b&#39;[null,{&#34;_numpy.ndarray.tolist()&#34;:[[&#34;0.3333333333333333&#34;,&#34;1.25&#34;],[&#34;4.826809000000001&#34;,&#34;text&#34;]],&#34;_type_orjson&#34;:&#34;&lt;U32&#34;},{&#34;_numpy.ndarray.tolist()&#34;:[[0,1],[4,4]],&#34;_type_orjson&#34;:&#34;int64&#34;},{&#34;_numpy.ndarray.tolist()&#34;:[[0,1],[4,4]],&#34;_type_orjson&#34;:&#34;int8&#34;}]&#39;
#     # &gt;&gt;&gt; import pandas as pd
#     # &gt;&gt;&gt; df = pd.DataFrame(
#     # ...     [[1/3, 5/4], [1.3**54, &#34;text&#34;]],
#     # ...     index=[&#34;row 1&#34;, &#34;row 2&#34;],
#     # ...     columns=[&#34;col 1&#34;, &#34;col 2&#34;],
#     # ... )
#     # &gt;&gt;&gt; df
#     #               col 1 col 2
#     # row 1  3.333333e-01  1.25
#     # row 2  1.422136e+06  text
#     # &gt;&gt;&gt; serialize_json(df)
#     # b&#39;{&#34;_obj.to_json()&#34;:&#34;{\\&#34;col 1\\&#34;:{\\&#34;row 1\\&#34;:0.3333333333,\\&#34;row 2\\&#34;:1422135.6537506874},\\&#34;col 2\\&#34;:{\\&#34;row 1\\&#34;:1.25,\\&#34;row 2\\&#34;:\\&#34;text\\&#34;}}&#34;,&#34;_type_orjson&#34;:&#34;&lt;class \&#39;pandas.core.frame.DataFrame\&#39;&gt;&#34;}&#39;
#     # &gt;&gt;&gt; s = pd.Series(
#     # ...     [1/3, 5/4, (1.3)**54, &#34;text&#34;],
#     # ...     index=[&#34;row 1&#34;, &#34;row 2&#34;, &#34;row 3&#34;, &#34;row 4&#34;],
#     # ... )
#     # &gt;&gt;&gt; s
#     # row 1          0.333333
#     # row 2              1.25
#     # row 3    1422135.653751
#     # row 4              text
#     # dtype: object
#     # &gt;&gt;&gt; serialize_json(s)
#     # b&#39;{&#34;_obj.to_json()&#34;:&#34;{\\&#34;row 1\\&#34;:0.3333333333,\\&#34;row 2\\&#34;:1.25,\\&#34;row 3\\&#34;:1422135.6537506874,\\&#34;row 4\\&#34;:\\&#34;text\\&#34;}&#34;,&#34;_type_orjson&#34;:&#34;&lt;class \&#39;pandas.core.series.Series\&#39;&gt;&#34;}&#39;
#     # &#34;&#34;&#34;
#     return dumps(obj, default=custom_orjson_encoder, option=OPT_SORT_KEYS)


# def deserialize_json(blob):
#     return json.loads(blob, object_hook=json_object_hook_decoder)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="lazydf.compression.bytes2integers"><code class="name flex">
<span>def <span class="ident">bytes2integers</span></span>(<span>bytes_content: bytes, n=4)</span>
</code></dt>
<dd>
<div class="desc"><p>Each 4 bytes become an int.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def bytes2integers(bytes_content: bytes, n=4):
    &#34;&#34;&#34;Each 4 bytes become an int.&#34;&#34;&#34;
    return [int.from_bytes(bytes_content[i : i + n], &#34;little&#34;) for i in range(0, len(bytes_content), n)]</code></pre>
</details>
</dd>
<dt id="lazydf.compression.deserialize_numpy"><code class="name flex">
<span>def <span class="ident">deserialize_numpy</span></span>(<span>blob)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def deserialize_numpy(blob):
    import numpy as np

    rest_of_header_len = blob[:10].split(b&#34;\xc2\xa7&#34;)[0]
    first_len = len(rest_of_header_len)
    header_len = first_len + int(rest_of_header_len)
    dims, dtype, hw = blob[first_len + 2 : header_len].split(b&#34;\xc2\xa7&#34;)
    dims = int(dims.decode())
    dtype = dtype.decode().rstrip()
    shape = bytes2integers(hw.ljust(4 * dims))

    dump = memoryview(blob)[header_len:]
    # dump = lz4.decompress(dump)
    m = np.frombuffer(dump, dtype=dtype)
    if dims &gt; 1:
        m = np.reshape(m, newshape=shape)
    return m</code></pre>
</details>
</dd>
<dt id="lazydf.compression.frompickle"><code class="name flex">
<span>def <span class="ident">frompickle</span></span>(<span>blob)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def frompickle(blob):
    prefix = blob[:7]
    blob = blob[7:]
    if prefix == b&#34;05pckl_&#34;:
        return pickle.loads(blob)
    elif prefix == b&#34;05dill_&#34;:
        import dill

        return dill.loads(blob)</code></pre>
</details>
</dd>
<dt id="lazydf.compression.integers2bytes"><code class="name flex">
<span>def <span class="ident">integers2bytes</span></span>(<span>lst, n=4) ‑> bytes</span>
</code></dt>
<dd>
<div class="desc"><p>Each int becomes N bytes. max=4294967294 for 4 bytes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def integers2bytes(lst, n=4) -&gt; bytes:
    &#34;&#34;&#34;Each int becomes N bytes. max=4294967294 for 4 bytes&#34;&#34;&#34;
    return b&#34;&#34;.join(d.to_bytes(n, byteorder=&#34;little&#34;) for d in lst)</code></pre>
</details>
</dd>
<dt id="lazydf.compression.pack"><code class="name flex">
<span>def <span class="ident">pack</span></span>(<span>obj, ensure_determinism, unsafe_fallback, compressed=True)</span>
</code></dt>
<dd>
<div class="desc"><pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; d = [[np.array([[1, 2/3], [4, 5]]), {&quot;x&quot;: b&quot;dsa&quot;}], [b&quot;asd&quot;, 5]]
&gt;&gt;&gt; blob = pack(d, ensure_determinism=True, unsafe_fallback=False)
&gt;&gt;&gt; unpack(blob)
[[array([[1.        , 0.66666667],
       [4.        , 5.        ]]), {'x': b'dsa'}], [b'asd', 5]]
&gt;&gt;&gt; blob = pack(d, compressed=False, ensure_determinism=True, unsafe_fallback=False)
&gt;&gt;&gt; unpack(blob)
[[array([[1.        , 0.66666667],
       [4.        , 5.        ]]), {'x': b'dsa'}], [b'asd', 5]]
&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; df = pd.DataFrame(np.array([[1, 2/3], [4, 5]]))
&gt;&gt;&gt; unpack(pack(df, ensure_determinism=True, unsafe_fallback=False))
     0         1
0  1.0  0.666667
1  4.0  5.000000
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pack(obj, ensure_determinism, unsafe_fallback, compressed=True):
    r&#34;&#34;&#34;
    &gt;&gt;&gt; import numpy as np
    &gt;&gt;&gt; d = [[np.array([[1, 2/3], [4, 5]]), {&#34;x&#34;: b&#34;dsa&#34;}], [b&#34;asd&#34;, 5]]
    &gt;&gt;&gt; blob = pack(d, ensure_determinism=True, unsafe_fallback=False)
    &gt;&gt;&gt; unpack(blob)
    [[array([[1.        , 0.66666667],
           [4.        , 5.        ]]), {&#39;x&#39;: b&#39;dsa&#39;}], [b&#39;asd&#39;, 5]]
    &gt;&gt;&gt; blob = pack(d, compressed=False, ensure_determinism=True, unsafe_fallback=False)
    &gt;&gt;&gt; unpack(blob)
    [[array([[1.        , 0.66666667],
           [4.        , 5.        ]]), {&#39;x&#39;: b&#39;dsa&#39;}], [b&#39;asd&#39;, 5]]
    &gt;&gt;&gt; import pandas as pd
    &gt;&gt;&gt; df = pd.DataFrame(np.array([[1, 2/3], [4, 5]]))
    &gt;&gt;&gt; unpack(pack(df, ensure_determinism=True, unsafe_fallback=False))
         0         1
    0  1.0  0.666667
    1  4.0  5.000000
    &#34;&#34;&#34;
    dump = traversal_enc(obj, ensure_determinism, unsafe_fallback)
    if compressed:
        import lz4.frame as lz4

        return b&#34;00lz4__&#34; + lz4.compress(dump)
    return dump</code></pre>
</details>
</dd>
<dt id="lazydf.compression.serialize_numpy"><code class="name flex">
<span>def <span class="ident">serialize_numpy</span></span>(<span>obj, ensure_determinism, unsafe_fallback, prefix=b'00nmpy_')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def serialize_numpy(obj, ensure_determinism, unsafe_fallback, prefix=b&#34;00nmpy_&#34;):
    import numpy as np

    if isinstance(obj, np.ndarray):
        if obj.dtype in [np.dtype(object)]:
            if unsafe_fallback:
                return topickle(obj, ensure_determinism)
            raise Exception(f&#34;Cannot handle this ndarray dtype: &#39;{np.dtype(object)}&#39;&#34;)

        dims = str(len(obj.shape))
        dtype = str(obj.dtype)
        rest_of_header = f&#34;§{dims}§{dtype}§&#34;.encode() + integers2bytes(obj.shape)
        rest_of_header_len = str(len(rest_of_header)).encode()
        header = rest_of_header_len + rest_of_header
        # return header + lz4.compress(ascontiguousarray(obj).data)
        return prefix + header + obj.data.tobytes()
    raise Exception(f&#34;Cannot handle this type &#39;{type(obj)}&#39;, check its shape or dtype&#34;)</code></pre>
</details>
</dd>
<dt id="lazydf.compression.topickle"><code class="name flex">
<span>def <span class="ident">topickle</span></span>(<span>obj, ensure_determinism)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def topickle(obj, ensure_determinism):
    try:
        try:
            prefix = b&#34;05pckl_&#34;
            dump = pickle.dumps(obj, protocol=5)
        except Exception as e:
            if ensure_determinism:  # pragma: no cover
                print(e)
                raise NondeterminismException(&#34;Cannot serialize deterministically.&#34;)
            import dill

            prefix = b&#34;05dill_&#34;
            dump = dill.dumps(obj, protocol=5)

        blob = prefix + dump
        return blob
    except KeyError as e:  # pragma: no cover
        if str(e) == &#34;&#39;__getstate__&#39;&#34;:  # pragma: no cover
            raise Exception(&#34;Unpickable value:&#34;, type(obj))
        else:
            raise e</code></pre>
</details>
</dd>
<dt id="lazydf.compression.traversal_dec"><code class="name flex">
<span>def <span class="ident">traversal_dec</span></span>(<span>dump)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def traversal_dec(dump):
    if isinstance(dump, bytes):
        header = dump[2:7]
        blob = dump[7:]
        if header == b&#34;json_&#34;:
            return orjson.loads(blob)
        if header == b&#34;bson_&#34;:
            return bson.decode(blob)[&#34;_&#34;]
        if header == b&#34;bint_&#34;:
            return int(blob.decode())
        if header == b&#34;nmpy_&#34;:
            return deserialize_numpy(blob)
        if header == b&#34;pddf_&#34;:
            from pandas import DataFrame

            return DataFrame(deserialize_numpy(blob))
        if header == b&#34;pdsr_&#34;:
            from pandas import Series

            return Series(deserialize_numpy(blob))
        if header == b&#34;trav_&#34;:
            return traversal_dec(bson.decode(blob)[&#34;_&#34;])
        if header in [b&#34;pckl_&#34;, b&#34;dill_&#34;]:
            return frompickle(dump)
        return dump
    if isinstance(dump, (int, str, bool)):
        return dump
    if isinstance(dump, list):
        lst = []
        for d in dump:
            lst.append(traversal_dec(d))
        return lst
    if isinstance(dump, dict):
        dic = {}
        for k, v in dump.items():
            dic[k] = traversal_dec(v)
        return dic
    raise Exception(f&#34;Cannot unpack {type(dump)}.&#34;)</code></pre>
</details>
</dd>
<dt id="lazydf.compression.traversal_enc"><code class="name flex">
<span>def <span class="ident">traversal_enc</span></span>(<span>obj, ensure_determinism, unsafe_fallback)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def traversal_enc(obj, ensure_determinism, unsafe_fallback):
    if isinstance(obj, bytes):
        return obj
    try:
        return b&#34;00json_&#34; + orjson.dumps(obj)
    except TypeError as e:
        pass
    try:
        return b&#34;00bson_&#34; + bson.encode({&#34;_&#34;: obj})
    except InvalidDocument as e:
        pass
    except OverflowError as o:
        if &#34;8-byte ints&#34; in str(o) and isinstance(obj, int):
            return b&#34;00bint_&#34; + str(obj).encode()
    klass = str(obj.__class__)
    if klass in [&#34;&lt;class &#39;numpy.ndarray&#39;&gt;&#34;]:
        return serialize_numpy(obj, ensure_determinism, unsafe_fallback)
    if klass in [&#34;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&#34;, &#34;&lt;class &#39;pandas.core.series.Series&#39;&gt;&#34;]:
        return serialize_numpy(obj.to_numpy(), ensure_determinism, unsafe_fallback, m[klass])
    if isinstance(obj, list):
        lst_of_bins = []
        for o in obj:
            lst_of_bins.append(traversal_enc(o, ensure_determinism, unsafe_fallback))
        return b&#34;00trav_&#34; + bson.encode({&#34;_&#34;: lst_of_bins})
    if unsafe_fallback:
        return topickle(obj, ensure_determinism)
    raise Exception(f&#34;Cannot pack {type(obj)}.&#34;)</code></pre>
</details>
</dd>
<dt id="lazydf.compression.unpack"><code class="name flex">
<span>def <span class="ident">unpack</span></span>(<span>blob)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def unpack(blob):
    if blob[:7] == b&#34;00lz4__&#34;:
        import lz4.frame as lz4

        blob = lz4.decompress(blob[7:])
    return traversal_dec(blob)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="lazydf.compression.NondeterminismException"><code class="flex name class">
<span>class <span class="ident">NondeterminismException</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Common base class for all non-exit exceptions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NondeterminismException(Exception):
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="lazydf" href="index.html">lazydf</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="lazydf.compression.bytes2integers" href="#lazydf.compression.bytes2integers">bytes2integers</a></code></li>
<li><code><a title="lazydf.compression.deserialize_numpy" href="#lazydf.compression.deserialize_numpy">deserialize_numpy</a></code></li>
<li><code><a title="lazydf.compression.frompickle" href="#lazydf.compression.frompickle">frompickle</a></code></li>
<li><code><a title="lazydf.compression.integers2bytes" href="#lazydf.compression.integers2bytes">integers2bytes</a></code></li>
<li><code><a title="lazydf.compression.pack" href="#lazydf.compression.pack">pack</a></code></li>
<li><code><a title="lazydf.compression.serialize_numpy" href="#lazydf.compression.serialize_numpy">serialize_numpy</a></code></li>
<li><code><a title="lazydf.compression.topickle" href="#lazydf.compression.topickle">topickle</a></code></li>
<li><code><a title="lazydf.compression.traversal_dec" href="#lazydf.compression.traversal_dec">traversal_dec</a></code></li>
<li><code><a title="lazydf.compression.traversal_enc" href="#lazydf.compression.traversal_enc">traversal_enc</a></code></li>
<li><code><a title="lazydf.compression.unpack" href="#lazydf.compression.unpack">unpack</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="lazydf.compression.NondeterminismException" href="#lazydf.compression.NondeterminismException">NondeterminismException</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>